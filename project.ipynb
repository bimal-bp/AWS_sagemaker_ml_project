{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraies \n",
    "\n",
    "import pandas as pd \n",
    "import json \n",
    "import boto3 \n",
    "import pathlib \n",
    "import io \n",
    "import sagemaker \n",
    "\n",
    "from sagemaker.deserializers import CSVDeserializer \n",
    "from sagemaker.serializers import CSVSerializer \n",
    "\n",
    "\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (ProcessingInput,ProcessingOutput,ScriptProcessor)\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline \n",
    "from sagemaker.workflow.steps import (ProcessingStep,TrainingStep,CreateModelStep)\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (ParameterInteger,ParameterFloat,ParameterString,ParameterBoolean)\n",
    "from sagemaker.workflow.clarify_check_step import (ModelBiasCheckConfig,ClarifyCheckStep,ModelExplainabilityCheckConfig)\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep \n",
    "from sagemaker.workflow.functions import JsonGet \n",
    "\n",
    "from sagemaker.workflow.lambda_step import (LambdaStep,LambdaOutputTypeEnum,LambdaOutput)\n",
    "from sagemaker.model_metrics import (MetricsSource,ModelMetrics,FileSource)\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiates aws session and client objects \n",
    "import sagemaker\n",
    "\n",
    "# Replace \"arn:aws:iam::905418308898:role/YOUR_SAGEMAKER_EXECUTION_ROLE_NAME\" with the ARN of your SageMaker execution role\n",
    "\n",
    "# Create the SageMaker session with the specified execution role ARN\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\",region_name = region)\n",
    "sm_client = boto3.client(\"sagemaker\",region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# fetch sm excutution role \n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "#s3 location where raw data to fetch \n",
    "read_bucket =\"sagemaker-sample-files\"\n",
    "read_prefix =\"datasets/tabular/synthetic_autombile_claims\"\n",
    "# data fetch \n",
    "raw_data_key = f\"s3://{read_bucket}/{read_prefix}\"\n",
    "#data upload \n",
    "processed_data_key=f\"{write_prefix}/processed\"\n",
    "train_data_key = f\"{write_prefix}/train\"\n",
    "validation_data_key=f\"{write_prefix}/validation\"\n",
    "test_data_key=f\"{write_prefix}/test\"\n",
    "\n",
    "# trai image \n",
    "training_image = retrive(framework=\"xgboost\",region=region,version=\"1.3-1\")\n",
    "\n",
    "# Full S3 paths\n",
    "claims_data_uri = f\"{raw_data_key}/claims.csv\"\n",
    "customers_data_uri = f\"{raw_data_key}/customers.csv\"\n",
    "output_data_uri = f\"s3://{write_bucket}/{write_prefix}/\"\n",
    "scripts_uri = f\"s3://{write_bucket}/{write_prefix}/scripts\"\n",
    "estimator_output_uri = f\"s3://{write_bucket}/{write_prefix}/training_jobs\"\n",
    "processing_output_uri = f\"s3://{write_bucket}/{write_prefix}/processing_jobs\"\n",
    "model_eval_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_eval\"\n",
    "clarify_bias_config_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_monitor/bias_config\"\n",
    "clarify_explainability_config_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_monitor/explainability_config\"\n",
    "bias_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify_output/pipeline/bias\"\n",
    "explainability_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify_output/pipeline/explainability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set names of pipeline objects \n",
    "pipeline_name =\"FraudDetectXGBPipeline\"\n",
    "pipeline_model_name=\"fraud-detect-xgb-pipeline\"\n",
    "model_package_group_name = \"fraud-detect-xgb-model-group\"\n",
    "base_job_name_prefix=\"fraud-detect\"\n",
    "endpoint_config_name =f\"{pipeline_model_name}-endpoint-config\"\n",
    "endpoint_name = f\"{pipeline_model_name}-endpoint\"\n",
    "\n",
    "#set the parameters \n",
    "target_col = \"fraud\"\n",
    "\n",
    "#set instance types and counts \n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "predictor_instance_count = 1 \n",
    "predictor_instance_type=\"ml.m4.xlarge\"\n",
    "clarify_instance_count = 1\n",
    "clarify_instance_type =\"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline input parameters\n",
    "\n",
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set deployment instance type\n",
    "deploy_instance_type_param = ParameterString(\n",
    "    name=\"DeployInstanceType\",\n",
    "    default_value=predictor_instance_type,\n",
    ")\n",
    "\n",
    "# Set deployment instance count\n",
    "deploy_instance_count_param = ParameterInteger(\n",
    "    name=\"DeployInstanceCount\",\n",
    "    default_value=predictor_instance_count\n",
    ")\n",
    "\n",
    "# Set Clarify check instance type\n",
    "clarify_instance_type_param = ParameterString(\n",
    "    name=\"ClarifyInstanceType\",\n",
    "    default_value=clarify_instance_type,\n",
    ")\n",
    "\n",
    "# Set model bias check params\n",
    "skip_check_model_bias_param = ParameterBoolean(\n",
    "    name=\"SkipModelBiasCheck\", \n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "register_new_baseline_model_bias_param = ParameterBoolean(\n",
    "    name=\"RegisterNewModelBiasBaseline\",\n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "supplied_baseline_constraints_model_bias_param = ParameterString(\n",
    "    name=\"ModelBiasSuppliedBaselineConstraints\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "# Set model explainability check params\n",
    "skip_check_model_explainability_param = ParameterBoolean(\n",
    "    name=\"SkipModelExplainabilityCheck\", \n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "register_new_baseline_model_explainability_param = ParameterBoolean(\n",
    "    name=\"RegisterNewModelExplainabilityBaseline\",\n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "supplied_baseline_constraints_model_explainability_param = ParameterString(\n",
    "    name=\"ModelExplainabilitySuppliedBaselineConstraints\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "# Set model approval param\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"Approved\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import pathlib\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-ratio\", type=float, default=0.8)\n",
    "    parser.add_argument(\"--validation-ratio\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--test-ratio\", type=float, default=0.1)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    logger.info(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    # Set local path prefix in the processing container\n",
    "    local_dir = \"/opt/ml/processing\"    \n",
    "    \n",
    "    input_data_path_claims = os.path.join(\"/opt/ml/processing/claims\", \"claims.csv\")\n",
    "    input_data_path_customers = os.path.join(\"/opt/ml/processing/customers\", \"customers.csv\")\n",
    "    \n",
    "    logger.info(\"Reading claims data from {}\".format(input_data_path_claims))\n",
    "    df_claims = pd.read_csv(input_data_path_claims)\n",
    "    \n",
    "    logger.info(\"Reading customers data from {}\".format(input_data_path_customers))\n",
    "    df_customers = pd.read_csv(input_data_path_customers)\n",
    "    \n",
    "    logger.debug(\"Formatting column names.\")\n",
    "    # Format column names\n",
    "    df_claims = df_claims.rename({c : c.lower().strip().replace(' ', '_') for c in df_claims.columns}, axis = 1)\n",
    "    df_customers = df_customers.rename({c : c.lower().strip().replace(' ', '_') for c in df_customers.columns}, axis = 1)\n",
    "    \n",
    "    logger.debug(\"Joining datasets.\")\n",
    "    # Join datasets\n",
    "    df_data = df_claims.merge(df_customers, on = 'policy_id', how = 'left')\n",
    "\n",
    "    # Drop selected columns not required for model building\n",
    "    df_data = df_data.drop(['customer_zip'], axis = 1)\n",
    "    \n",
    "    # Select Ordinal columns\n",
    "    ordinal_cols = [\"police_report_available\", \"policy_liability\", \"customer_education\"]\n",
    "\n",
    "    # Select categorical columns and filling with na\n",
    "    cat_cols_all = list(df_data.select_dtypes('object').columns)\n",
    "    cat_cols = [c for c in cat_cols_all if c not in ordinal_cols]\n",
    "    df_data[cat_cols] = df_data[cat_cols].fillna('na')\n",
    "    \n",
    "    logger.debug(\"One-hot encoding categorical columns.\")\n",
    "    # One-hot encoding categorical columns\n",
    "    df_data = pd.get_dummies(df_data, columns = cat_cols)\n",
    "    \n",
    "    logger.debug(\"Encoding ordinal columns.\")\n",
    "    # Ordinal encoding\n",
    "    mapping = {\n",
    "               \"Yes\": \"1\",\n",
    "               \"No\": \"0\" \n",
    "              }\n",
    "    df_data['police_report_available'] = df_data['police_report_available'].map(mapping)\n",
    "    df_data['police_report_available'] = df_data['police_report_available'].astype(float)\n",
    "\n",
    "    mapping = {\n",
    "               \"15/30\": \"0\",\n",
    "               \"25/50\": \"1\", \n",
    "               \"30/60\": \"2\",\n",
    "               \"100/200\": \"3\"\n",
    "              }\n",
    "    \n",
    "    df_data['policy_liability'] = df_data['policy_liability'].map(mapping)\n",
    "    df_data['policy_liability'] = df_data['policy_liability'].astype(float)\n",
    "\n",
    "    mapping = {\n",
    "               \"Below High School\": \"0\",\n",
    "               \"High School\": \"1\", \n",
    "               \"Associate\": \"2\",\n",
    "               \"Bachelor\": \"3\",\n",
    "               \"Advanced Degree\": \"4\"\n",
    "              }\n",
    "    \n",
    "    df_data['customer_education'] = df_data['customer_education'].map(mapping)\n",
    "    df_data['customer_education'] = df_data['customer_education'].astype(float)\n",
    "    \n",
    "    df_processed = df_data.copy()\n",
    "    df_processed.columns = [c.lower() for c in df_data.columns]\n",
    "    df_processed = df_processed.drop([\"policy_id\", \"customer_gender_unkown\"], axis=1)\n",
    "    \n",
    "    # Split into train, validation, and test sets\n",
    "    train_ratio = args.train_ratio\n",
    "    val_ratio = args.validation_ratio\n",
    "    test_ratio = args.test_ratio\n",
    "    \n",
    "    logger.debug(\"Splitting data into train, validation, and test sets\")\n",
    "    \n",
    "    y = df_processed['fraud']\n",
    "    X = df_processed.drop(['fraud'], axis = 1)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_ratio, random_state=42)\n",
    "\n",
    "    train_df = pd.concat([y_train, X_train], axis = 1)\n",
    "    val_df = pd.concat([y_val, X_val], axis = 1)\n",
    "    test_df = pd.concat([y_test, X_test], axis = 1)\n",
    "    dataset_df = pd.concat([y, X], axis = 1)\n",
    "    \n",
    "    logger.info(\"Train data shape after preprocessing: {}\".format(train_df.shape))\n",
    "    logger.info(\"Validation data shape after preprocessing: {}\".format(val_df.shape))\n",
    "    logger.info(\"Test data shape after preprocessing: {}\".format(test_df.shape))\n",
    "    \n",
    "    # Save processed datasets to the local paths in the processing container.\n",
    "    # SageMaker will upload the contents of these paths to S3 bucket\n",
    "    logger.debug(\"Writing processed datasets to container local path.\")\n",
    "    train_output_path = os.path.join(f\"{local_dir}/train\", \"train.csv\")\n",
    "    validation_output_path = os.path.join(f\"{local_dir}/val\", \"validation.csv\")\n",
    "    test_output_path = os.path.join(f\"{local_dir}/test\", \"test.csv\")\n",
    "    full_processed_output_path = os.path.join(f\"{local_dir}/full\", \"dataset.csv\")\n",
    "\n",
    "    logger.info(\"Saving train data to {}\".format(train_output_path))\n",
    "    train_df.to_csv(train_output_path, index=False)\n",
    "    \n",
    "    logger.info(\"Saving validation data to {}\".format(validation_output_path))\n",
    "    val_df.to_csv(validation_output_path, index=False)\n",
    "\n",
    "    logger.info(\"Saving test data to {}\".format(test_output_path))\n",
    "    test_df.to_csv(test_output_path, index=False)\n",
    "    \n",
    "    logger.info(\"Saving full processed data to {}\".format(full_processed_output_path))\n",
    "    dataset_df.to_csv(full_processed_output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import  PipelineSession \n",
    "\n",
    "# uploading preprocessing.script to s3 \n",
    "s3_client.upload_file(\n",
    "    Filename=\"preprocessing.py\",bucket=write_bucket,key=f\"{write_prefix}/scripts/preprocessing.py\"\n",
    "\n",
    ")\n",
    "\n",
    "# define preprocessing sklearn configuration \n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role =sagemaker_role,\n",
    "    instance_count = 1,\n",
    "    instance_type = process_instance_type,\n",
    "    base_job_name =f\"{base_job_name_prefix}-processing\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Define pipeline \n",
    "process_step = ProcessingStep(\n",
    "    name= \"DataProcessing\",\n",
    "    processor = sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=claims_data_uri,destination=\"/opt/ml/processing/claims\")\n",
    "        ProcessingInput(source=customers_data_uri,destination=\"/opt/ml/procssing/customers\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/train_data\",output_name=\"train_data\",source=\"/opt/ml/processing/train\")\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/validation_data\",output_name=\"validation_data\",source=\"/opt/ml/processing/val\")\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/test_data\",output_name=\"test_data\",source=\"/opt/ml/processing/test\")\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/processed_data\",output_name=\"processed_data\",source=\"/opt/ml/processing/full\")\n",
    "\n",
    "\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--train-ration\",\"0.8\",\n",
    "        \"--validation-ratio\",\"0.1\",\n",
    "        \"--test-ratio\",\"0.1\"\n",
    "    ],\n",
    "\n",
    "    code = f\"s3://{write_bucket}/{write_prefix}/scripts/preprocessing.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile xgboost_train.py  \n",
    "\n",
    "import argparse \n",
    "import os \n",
    "import joblib \n",
    "import json \n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentsParser()\n",
    "\n",
    "    # Hyperparameters and algorithm parameters \n",
    "    parser.add_argument(\"--num_round\",type= int ,default=100)\n",
    "    parser.add_argument(\"--max_depth\",type=int ,default=3)\n",
    "    parser.add_argument(\"--eta\",type=float,default=0.2)\n",
    "    parser.add_argument(\"--subsample\",type=float,default=0.9)\n",
    "    parser.add_argument(\"--colsample_bytree\",type=float,default=0.8)\n",
    "    parser.add_argument(\"--objective\",type=str,default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--eval_metric\",type=str,default=\"auc\")\n",
    "    parser.add_argument(\"--nfold\",type=int,default=3)\n",
    "    parser.add_argument(\"--early-stopping-rounds\",type=int,default=3)\n",
    "\n",
    "\n",
    "\n",
    "    #set location of data \n",
    "    parser.add_argument(\"--train_data_dir\",type=str,default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation_data_dir\",type=str,default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--model_dir\",type=str,default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--output_data_dir\",type=str,default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_train=pd.read_csv(f\"{args.train_data_dir}/train.csv\")\n",
    "    train=data_train.drop(\"fraud\",axis=1)\n",
    "    label_train=pd.DataFrame(data_train[\"fraud\"])\n",
    "    dtrain = xgb.DMatrix(train,label=label_train)\n",
    "\n",
    "    data_validation = pd.read_csv(f\"{args.validation_data_dir}/validation.csv\")\n",
    "    validation = data_validation.drop(\"fraud\",axis=1)\n",
    "    label_validation = pd.DataFrame(data_validation[\"fraud\"])\n",
    "    dvalidation=xgb.DMatrix(validation,label=label_validation)\n",
    "\n",
    "    #choose hyperparameter \n",
    "    params = {\"max_depth\":args.max_depth,\n",
    "              \"eta\":args.eta,\n",
    "              \"objective\":args.objective,\n",
    "              \"subsample\":args.subsample,\n",
    "              \"colsample_bytree\":args.colsample_bytree}\n",
    "\n",
    "    num_boost_round = args.num_round \n",
    "    n_fold = args.nfold\n",
    "    early_stopping_rounds = args.early_stopping_rounds\n",
    "\n",
    "    # cross validation \n",
    "    cv_results=xgb.cv(\n",
    "        params = params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=[\"auc\"],\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    model = xgb.train(params=params,dtrain=dtrain,num_boost_round=len(cv_results))\n",
    "\n",
    "    train_pred = model.predict(dtrain)\n",
    "    validation_pred = model.predict(dvalidation)\n",
    "\n",
    "    train_auc = roc_auc_score(label_train,train_pred)\n",
    "    validation_auc = roc_auc_score(label_validation,validation_pred)\n",
    "\n",
    "\n",
    "\n",
    "    metric_data={\"hyperparameters\":params,\n",
    "                 \"binary_classification_metrics\":{\"validation:auc\":{\"value\":validation_auc}\n",
    "                                                  \"train:auc\":{\"value\":train_auc}}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    metric_location = args.output_data_dir+\"/metric.json\"\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "\n",
    "    with open(metric_location,\"w\") as f:\n",
    "        json.dump(metric_data,f)\n",
    "    with open(model_location,\"wb\") as f:\n",
    "        joblib.dump(model,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
